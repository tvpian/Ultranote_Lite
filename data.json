{
  "version": 1,
  "settings": {
    "rollover": true,
    "seenTip": true,
    "autoCarryTasks": false,
    "dailyTemplate": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\n\n## Journal\n\n## Wins\n",
    "scratchpad": "1) Journal the methods and the results obtained while trying out for Test the visuals from UR10E on UR5E to improve realism\n2) Look at the automated service startup script\n\nUltranote:\n1. Scratchpad refresh problem\n2. Needs better handling of the past tasks - should handle cases where it gets carelessly deleted\n3. History of completed tasks\n4. The idea of the week in the review section should be improved\n5. Better analytics\n6. Better readability in the notes section MD\n7. Today's task glitches for the first entry to add an item\n",
    "theme": "dark"
  },
  "projects": [
    {
      "id": "x58sfrwh",
      "name": "Digital Twin",
      "createdAt": "2025-08-13T17:33:08.301Z"
    },
    {
      "id": "lpliw12c",
      "name": "Motion Planner",
      "createdAt": "2025-08-13T20:01:18.709Z"
    },
    {
      "id": "a7732c0q",
      "name": "Perception Service",
      "createdAt": "2025-08-13T20:03:29.029Z"
    },
    {
      "id": "c7szb5bi",
      "name": "Robot Learning",
      "createdAt": "2025-08-14T17:14:15.270Z"
    }
  ],
  "notes": [
    {
      "id": "rfn667g2",
      "title": "2025-08-13 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\nImport URDF to Issac Sim\nLearning how to interface hardware with the simulation \n - Do it with UR5e and Robotiq - Gello\n - As first step try with Joint Trajectory Control like UI\n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-13",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-13T04:20:20.955Z",
      "updatedAt": "2025-08-14T16:27:52.019Z"
    },
    {
      "id": "tzt5jxe4",
      "title": "Model Anomalies",
      "content": "- Presence of white screen - Model overfit problem\n- False Positives \n - Color biases - Yellow and Black color misidentification\n - Shadow and lighting \n - Range - Close and Far",
      "tags": [],
      "projectId": "a7732c0q",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-13T20:07:50.366Z",
      "updatedAt": "2025-08-13T20:07:50.366Z"
    },
    {
      "id": "5zkaojpo",
      "title": "2025-08-14 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\nImport URDF to Issac Sim\nLearning how to interface hardware with the simulation \n - Do it with UR5e and Robotiq - Gello\n - As first step try with Joint Trajectory Control like UI\nComplete the 3 videos on DTwin\nIssacLab(2)\nThink about how a personal work setup for robot learning can be built\n\n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-14",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-14T17:01:30.445Z",
      "updatedAt": "2025-08-14T17:13:45.629Z"
    },
    {
      "id": "1l4evqz6",
      "title": "2025-08-15 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\n- Test Joint-State Controller on the UR5e with Robotiq gripper\n - Go through the Franka Panda Example\n - Control the joint states from ros node\n - Learn and implement how to expose the joint state controller as a subscriber\n\n- Custom Teleop Setup Ideas and Design\n\n- Finish backlog tasks(2)\n\n\n\n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-15",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-15T01:40:18.036Z",
      "updatedAt": "2025-08-15T20:08:33.308Z"
    },
    {
      "id": "t0ypufuu",
      "title": "URDF import in Isaacsim",
      "content": "In Isaacsim V5 by default, as per the instructions, when I tried to source the ROS2 workspace and tried to import the UR5e URDF, it was causing errors.\nWhat worked so far is using the absolute paths to mesh files.\n\nSecondly, having conflicting frame names like 'world' or 'World' dint seem like a problem.\n\nAll additional ROS 2-specific tags didn't cause any trouble in the import procedure.\n\nInitially, the movements of the joints seemed very abrupt. After setting the natural frequency to 300 for all the joints, it stabilized.\n\nSimilarly, on putting the natural frequency as 300 for the Robotiq gripper, it got stabilized as well.\n\nBasically for all the position based joints the natural frequency is set to 300 and for all the mimic joints, its set to 2500\n\nTwo errors that consistently showed up and dint get resolved yet \n - Limits not set for the left inner knuckle joint.\n - Multiple reference joints for the left inner knuckle joint.\n\n\n# Run this in Script Editor (Python) after your robot is loaded\n\nimport math\nimport omni.usd\nfrom pxr import Usd, Sdf, UsdPhysics   # Revolute joint attributes live here\nfrom pxr import PhysxSchema            # PhysxMimicJointAPI (multiple-apply schema)\n\nstage: Usd.Stage = omni.usd.get_context().get_stage()  # correct way to get the current stage in Kit apps\n# (Docs: omni.usd UsdContext/get_stage)  # https://docs.omniverse.nvidia.com/dev-guide/latest/programmer_ref/usd/stage/get-current-stage.html\n\ndef set_single_reference(follower_prim_path: str, source_joint_path: str):\n    prim = stage.GetPrimAtPath(follower_prim_path)\n    if not prim.IsValid():\n        print(\"Invalid prim:\", follower_prim_path); return\n    # A prim can have multiple mimic-API instances (rotX/rotY/rotZ). Fix all of them.\n    for api in PhysxSchema.PhysxMimicJointAPI.GetAll(prim):\n        # Keep exactly one referenceJoint target\n        rel = api.GetReferenceJointRel()\n        rel.ClearTargets(True)              # clear authored targets across the layer stack\n        rel.AddTarget(Sdf.Path(source_joint_path))\n        # Ensure gearing/offset exist (matches URDF defaults)\n        if api.GetGearingAttr().Get() is None:\n            api.CreateGearingAttr(1.0)\n        if api.GetOffsetAttr().Get() is None:\n            api.CreateOffsetAttr(0.0)\n        #print(f\"[OK] {follower_prim_path} -> reference {source_joint_path} (instance {api.GetName()})\")\n\ndef set_revolute_limits_rad(joint_path: str, lower_rad: float, upper_rad: float):\n    \"\"\"\n    Author finite limits on a UsdPhysics.RevoluteJoint. Converts radians->degrees for USD.\n    \"\"\"\n    prim = stage.GetPrimAtPath(joint_path)\n    if not prim.IsValid():\n        print(\"Invalid prim:\", joint_path); return\n    if not prim.IsA(UsdPhysics.RevoluteJoint):\n        print(\"Not a UsdPhysics.RevoluteJoint:\", joint_path); return\n    j = UsdPhysics.RevoluteJoint(prim)\n    lo_deg = math.degrees(lower_rad)\n    hi_deg = math.degrees(upper_rad)\n    # Create*/Get* are equivalent for authoring; Create* guarantees the attr exists.\n    j.CreateLowerLimitAttr().Set(lo_deg)\n    j.CreateUpperLimitAttr().Set(hi_deg)\n    print(f\"[OK] Set limits on {joint_path} to [{lo_deg:.3f}°, {hi_deg:.3f}°]\")\n\n# ---- Your existing mimic fixes (keep these) ----\nset_single_reference(\"/World/ur/joints/robotiq_85_left_inner_knuckle_joint\",  \"/World/ur/joints/robotiq_85_left_knuckle_joint\")\nset_single_reference(\"/World/ur/joints/robotiq_85_left_finger_tip_joint\",     \"/World/ur/joints/robotiq_85_left_knuckle_joint\")\nset_single_reference(\"/World/ur/joints/robotiq_85_right_inner_knuckle_joint\", \"/World/ur/joints/robotiq_85_left_knuckle_joint\")\nset_single_reference(\"/World/ur/joints/robotiq_85_right_finger_tip_joint\",    \"/World/ur/joints/robotiq_85_left_knuckle_joint\")\n\n# ---- NEW: author finite limits on both inner knuckle joints ----\n# left inner knuckle: +1 mapping of source [0, 0.8] rad\nset_revolute_limits_rad(\"/World/ur/joints/robotiq_85_left_inner_knuckle_joint\",  0.0,  0.8)\n\n# right inner knuckle: -1 mapping of source -> [-0.8, 0] rad\nset_revolute_limits_rad(\"/World/ur/joints/robotiq_85_right_inner_knuckle_joint\", -0.8, 0.0)\n",
      "tags": [
        "urdf",
        "isaacsim",
        "digitaltwin"
      ],
      "projectId": "x58sfrwh",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-15T01:47:05.036Z",
      "updatedAt": "2025-08-21T18:01:06.194Z",
      "attachments": []
    },
    {
      "id": "drfcs1d6",
      "title": "Use the Accelerometer based glove fore Teleoperation",
      "content": "- Use the gloves from the shelf and set it up.\n- Set it up to work with ROS2 topics\n- Test to see if teleoperation can be achieved using cartesian controller\n- Collect test dataset\n- Understand and retarget the collected data to train the policy",
      "tags": [
        "teleoperation",
        "digitaltwin",
        "isaacsim"
      ],
      "projectId": null,
      "dateIndex": null,
      "type": "idea",
      "pinned": false,
      "createdAt": "2025-08-15T01:55:20.529Z",
      "updatedAt": "2025-08-15T02:07:02.013Z"
    },
    {
      "id": "95ds18dm",
      "title": "Teleoperation Survey",
      "content": "# Research Summary: [Tele-operation Survey]\n\n## Objective\nLearn about the various teleoperation devices used in the community\n\n## Key Findings\n- Teleoperation as a technique can be thought of a classic Master-Apprentice relationship\n- The robot the apprentice learns the craft by watching the humans, the masters at work\n- Paradigm shift from coding instructions to teaching by doing\n- Traditional Code - Rigid, specific and totally inflexible. Works on an assembly line\n- Human Demonstrations - Fluid, intuitive. It captures not just 'what' but also 'how'\n- How to Demonstrate:\n - Kin-esthetic Teaching: Physically guiding the robot's arm\n - Teleoperation: Using a joystick or simple controller\n - Immersive VR: Using a VR headset to become the robot - Most intuitive\n - Operators being able to step into the robot's body is the most intuitive way for teaching robots.\n - Immersive VR techniques lets operator's movements get consumed to directly control the gripper\n   - Operator hand movement mapped one to one with the gripper\n   - Operator intuition gets captured more accurately. Higher quality data\n - Apprentice Mind:\n  - Imitation Learning - A paradigm where an agent learns to perform a task by mimicking the behavior of an expert.\n   - Behavioral Cloning - Learn to map a specific state to a specific action\n                          Not just enough to mimic the past but also learn the patterns to predict and generalize.\n - Good teaching requires a closed feedback.\n  - Robot needs to 'talk' back - \n   - Augmented Reality - Visualize the planned path.\n   - Haptic Feedback - Vibrates to show confidence\n   - Auditory Cues - Sound to indicate status or intent\n\n\n\n \n## Implications\n\n## Next Steps\n",
      "tags": [],
      "projectId": "c7szb5bi",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-15T23:34:07.907Z",
      "updatedAt": "2025-08-16T00:16:05.904Z",
      "attachments": []
    },
    {
      "id": "m99i6s3b",
      "title": "2025-08-17 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-17",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-18T01:11:18.417Z",
      "updatedAt": "2025-08-18T01:11:20.295Z",
      "attachments": []
    },
    {
      "id": "tho7b72v",
      "title": "2025-08-18 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\nChatgpt5 Analysis:\n- The performance on the MMMU metric has increased by 5%.\n- Features:\n - Model Selection - gpt5 main(fast) & gpt5 thinking(reasoning) - Router(trained model on prompts) decides which model to be used for specific prompts\n - Hallucination - Typically browsing tools like RAGS are used to ground the response of the LLM models to reduce hallucination\n - Sycophancy - Because of RLHF - Mitigated with the help of System Prompts - Fragile during long conversation - Handled using Post Training\n  - Models were penalized when it mistook factual agreement with tone politeness\n- Safe Completion - Fully Comply or Hard Refuse - Model trained to give 3 prompts - 1) Direct Answer 2) Safe Completion 3) Refuse\n- Deception - Happens when the graders during post-training rewarded confident looking answer although the reasoning behind it was invalid - GPT5 trained to Fail Gracefully and also supports \n              Chain Of Thought Monitoring - Honest and valid COT are rewarded while anything else are severely penalized. \n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-18",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-18T04:21:34.888Z",
      "updatedAt": "2025-08-20T00:47:00.337Z",
      "attachments": []
    },
    {
      "id": "dddvyov0",
      "title": "2025-08-19 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\n\n## Journal\n### Tedx Daily:\n- It's not enough to have the right attitude but also the behaviour associated with the kind of attitude you want to have\n- 6 behaviours:\n - Count yourself in. \n  - Stand up to conflict if it's required.\n - Give yourself 20secs of courage\n - Take a seat at the table\n - Cheer for other peoples success\n - Bolster your confidence for a new activity through youralready great performance in another. Use prior success to propel yourself forward.\n - Celebrate confidently.\n\n### Veritasium:\n- For the longest time it was believed that to observe The Law of Large Numbers independence between events was necessary. Also the corollary that if you saw the \n  Law of Large Numbers coming into existense it means there lies indepence between events.\n- If the Law of Large Numbers is thought of as an absolute idea then it can be said that all decisions are acts of free will. Hence in a way it could be said that\n  free will can be measured.\n- Markov proved that TLOL applied even to dependent events thereby proving observing convergence in social statistics dint necessarily mean that the decisions                   \n  are independent.\n- Any or most events could be defined as a Markov Chain Event\n- Claude Shannon came up with the idea that if probability of next letter can be predictedd why not the next word itself.\n- Current LLMs not just predict the next word/token based on probability but also uses Attention as a concept.\n- Google is fundamentally build on PageRank alogorithm based on MCC\n- Memoryless property of MC - very powerful\n\n\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-19",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-19T06:21:48.183Z",
      "updatedAt": "2025-08-19T19:34:37.284Z",
      "attachments": []
    },
    {
      "id": "up18btk1",
      "title": "Teleoperation Survey - Part 2",
      "content": "# Research Summary: [Tele-operation Survey]\n\n## Objective\nLearn about the various teleoperation devices used in the community\n\n## Key Findings\n- Historically, teaching robots and obtaining the internal state of the robot back were looked at as separate branches.\n- Two high-level ways of robot learning:\n - Human in the loop Reinforcement Learning - Human Occupancy, Reward at the end of the task, Binary reward system(1-success, 0-fail)\n - Active Learning\n- Rather than copying the action space of the humans, the robot is trying to learn the reward function set by the humans.,\n- In Imitation Learning, a form of Active Learning, the robots instead of learning the reward, the robot directly learns the control policy.\n- RL is the why, and IL is the how\n- Demonstration Learning - Significantly less amount of data required.\n- Moving away from the need for expert coders for everyday users\n- Starting with a policy learnt from humans is technically a lot safer than starting random\n- Batch Learning - Collects several corrections and updates the model once.\n- Realtime - Online gradient descent, the robots in this case, tweak their learning every time a correction is given - Tighter Loop\n-\n\n\n\nIndirect Teaching:\n\n-\n\n- Demonstrations have to collect the state space of the task accurately, implying all the possible object locations, orientations, and positions.\n - For complex tasks, the task space is enormous.\n- Generalization tends to be tough because the data we collect doesn't always tend to be statistically neat and IID\n- Whenever there is a shift in the observation space, this leads to a Distributional Shift problem.\n- Teleoperation could give slightly cleaner data—Interactive Imitation Learning - Motivates addressing new situations on the fly.\n- Augmented Reality could help in projecting potential waypoints in the 3D space for validation of performance.\n- Haptic feedback, like pulses, could signify the confidence of the robot in executing a task.\n- Multimodal feedback is good to build trust, but not too much, though—a primary source to obtain the key info and a secondary source for nuances.\n\nWhat are the tangible outputs of having a closed-loop teaching-learning framework?\n - Human trust in the robot improves significantly.\n - Leads to Human-Robot Co-Adaptation.\n - With steady feedback, humans could become better teachers.\n - Robots that communicate explicitly are considered more trustworthy.\n\n\nHow is learning implemented?\n- Few-shot generalization.\n\n \n## Implications\n\n## Next Steps\n",
      "tags": [],
      "projectId": "c7szb5bi",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-19T21:28:51.578Z",
      "updatedAt": "2025-08-20T01:36:03.972Z",
      "attachments": []
    },
    {
      "id": "78exhcxi",
      "title": "2025-08-20 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-20",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-20T18:15:36.346Z",
      "updatedAt": "2025-08-20T20:38:45.365Z",
      "attachments": []
    },
    {
      "id": "498mkuqj",
      "title": "Agent integration with IntraChat",
      "content": "1. It should be the one-stop control for the team to talk with the services and server.\n2. One LLM-based interactive portal for starting demos.",
      "tags": [
        "llm",
        "agent",
        "intrachat"
      ],
      "projectId": null,
      "dateIndex": null,
      "type": "idea",
      "pinned": false,
      "createdAt": "2025-08-20T19:24:22.221Z",
      "updatedAt": "2025-08-20T19:29:41.655Z",
      "attachments": []
    },
    {
      "id": "rhsvuali",
      "title": "2025-08-21 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\nMaster Robot Assembly process and Document the learning\n - Split the urdf into arm and gripper\n - Test the robot assembler - Documentation method\n - Test the fixed joint way - Lychee Ai method\nComplete Teleoperation Survey\n - Create 1 slide \n - Use the CG reference. Combine it with the NLM \nControl the gripper thorugh Python code\n - Test with Megumi code\n - Test in the script editor\nComplete Isaac Sim Documentaion\n - Test the arm handle functions with ur \n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-21",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-21T15:56:02.810Z",
      "updatedAt": "2025-08-21T17:27:23.110Z",
      "attachments": []
    },
    {
      "id": "f9g9ypih",
      "title": "Robot Control From the Script ",
      "content": "```python\n# --- Robotiq 85 single-joint control (init-safe, frame-update loop, robust World init) ---\n\nimport time\nimport numpy as np\n\n# ===== Imports compatible with Isaac Sim 4.x/5.x =====\ntry:\n    # Isaac Sim 5.x-style package names\n    from isaacsim.core.api import World\n    from isaacsim.core.utils.types import ArticulationAction\n    from isaacsim.robot.manipulators import SingleManipulator\nexcept Exception:\n    # Fallback for older builds\n    from omni.isaac.core import World\n    from omni.isaac.core.utils.types import ArticulationAction\n    from omni.isaac.core.robots import SingleManipulator  # older alias\n\ntry:\n    # 5.x\n    from isaacsim.core.articulations import ArticulationView\nexcept Exception:\n    from omni.isaac.core.articulations import ArticulationView\n\nimport omni.kit.app\nimport omni.timeline\nimport omni.usd\nfrom pxr import Usd\n\n# === Your scene paths ===\nROBOT_PRIM_PATH = \"/World/ur\"\nEE_LINK_PATH    = \"/World/ur/wrist_3_link/flange/tool0\"\nGRIPPER_JOINT   = \"robotiq_85_left_knuckle_joint\"\n\nOPEN_POS   = 0.00\nCLOSED_POS = 0.8\nSTEP       = 0.01\n\nBASE_NAME = \"__robotiq_single_joint_manip__\"\nVIEW_NAME = \"__robotiq_robot_view__\"\n\n# --- Helper: make sure the prim exists before proceeding ---\ndef _assert_prim_exists(path: str) -> bool:\n    stage = omni.usd.get_context().get_stage()\n    if stage is None:\n        print(\"[robotiq] No USD stage yet. Load/open a stage first.\")\n        return False\n    prim = stage.GetPrimAtPath(path)\n    if not prim.IsValid():\n        print(f\"[robotiq] Robot prim not found: {path}\")\n        roots = [p.GetPath().pathString for p in stage.GetPseudoRoot().GetChildren()]\n        print(\"[robotiq] Top-level prims:\", roots[:10])\n        return False\n    return True\n\n# --- Robust World acquisition/creation ---\nworld = None\ntry:\n    world = World.instance()\nexcept Exception:\n    world = None\n\nif world is None or getattr(world, \"scene\", None) is None:\n    world = World(stage_units_in_meters=1.0)\n\n# 1) Ensure an ArticulationView exists and physics is initialized\nif not _assert_prim_exists(ROBOT_PRIM_PATH):\n    raise RuntimeError(\"Load a scene that contains your robot at /World/ur (or update ROBOT_PRIM_PATH).\")\n\nview = world.scene.get_object(VIEW_NAME)\nif view is None:\n    view = ArticulationView(prim_paths_expr=ROBOT_PRIM_PATH, name=VIEW_NAME)\n    world.scene.add(view)\n\ntry:\n    world.initialize_physics()\nexcept Exception:\n    try:\n        world.reset()\n    except Exception:\n        pass\n\n# 2) Wrap the articulation (non-destructive) and add if missing\nmanip = world.scene.get_object(BASE_NAME)\nif manip is None:\n    manip = SingleManipulator(\n        prim_path=ROBOT_PRIM_PATH,\n        name=BASE_NAME,\n        end_effector_prim_path=EE_LINK_PATH,\n        gripper=None,\n    )\n    world.scene.add(manip)\n\n# Resolve joint index\njoint_names = manip.dof_names\nname_to_idx = {n: i for i, n in enumerate(joint_names)}\nif GRIPPER_JOINT not in name_to_idx:\n    print(\"[robotiq] Joint not found:\", GRIPPER_JOINT)\n    print(\"[robotiq] Available DOFs:\", joint_names)\n    raise RuntimeError(\"Update GRIPPER_JOINT.\")\nJIDX = name_to_idx[GRIPPER_JOINT]\nLOW, HIGH = (min(OPEN_POS, CLOSED_POS), max(OPEN_POS, CLOSED_POS))\n\n# 3) Frame update loop (guarded until sim/joints are ready)\napp = omni.kit.app.get_app()\ntimeline = omni.timeline.get_timeline_interface()\n\nold_sub = getattr(manip, \"_robotiq_sub\", None)\nif old_sub is not None:\n    try:\n        old_sub.unsubscribe()\n    except Exception:\n        pass\n\n_state = {\"i\": 0}\n\ndef _clamp(v, lo, hi): \n    return lo if v < lo else hi if v > hi else v\n\ndef _on_update(e):\n    if not timeline.is_playing():\n        return\n\n    q = manip.get_joint_positions()\n    if q is None or len(q) == 0:\n        return\n\n    i = _state[\"i\"]\n    if i < 500:\n        q[JIDX] = _clamp(q[JIDX] + STEP, LOW, HIGH)  # closing\n    else:\n        q[JIDX] = _clamp(q[JIDX] - STEP, LOW, HIGH)  # opening\n    manip.apply_action(ArticulationAction(joint_positions=q.tolist()))\n    _state[\"i\"] = 0 if i >= 999 else i + 1\n\nmanip._robotiq_sub = app.get_update_event_stream().create_subscription_to_pop(\n    _on_update, name=f\"__robotiq_update_{int(time.time())%100000}\"\n)\n\ntimeline.play()\nprint(f\"[robotiq] Driving '{GRIPPER_JOINT}' with open/close loop (guarded for sim init).\")\n\n# --- Utilities ---\ndef gripper_set(alpha: float):\n    a = float(np.clip(alpha, 0.0, 1.0))\n    target = OPEN_POS * (1.0 - a) + CLOSED_POS * a\n    q = manip.get_joint_positions()\n    if q is None: \n        print(\"[robotiq] Joint state not ready yet.\"); return\n    q[JIDX] = _clamp(target, LOW, HIGH)\n    manip.apply_action(ArticulationAction(joint_positions=q.tolist()))\n    print(f\"[robotiq] Set alpha={a:.2f} -> {q[JIDX]:.3f}\")\n\ndef gripper_open():\n    q = manip.get_joint_positions()\n    if q is None: \n        print(\"[robotiq] Joint state not ready yet.\"); return\n    q[JIDX] = OPEN_POS\n    manip.apply_action(ArticulationAction(joint_positions=q.tolist()))\n    print(\"[robotiq] Open.\")\n\ndef gripper_close():\n    q = manip.get_joint_positions()\n    if q is None: \n        print(\"[robotiq] Joint state not ready yet.\"); return\n    q[JIDX] = CLOSED_POS\n    manip.apply_action(ArticulationAction(joint_positions=q.tolist()))\n    print(\"[robotiq] Close.\")\n\ndef gripper_stop_loop():\n    sub = getattr(manip, \"_robotiq_sub\", None)\n    if sub is not None:\n        try:\n            sub.unsubscribe()\n            print(\"[robotiq] Stopped auto loop.\")\n        except Exception:\n            print(\"[robotiq] Could not unsubscribe (already gone?).\")\n",
      "tags": [],
      "projectId": "x58sfrwh",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-21T18:01:43.089Z",
      "updatedAt": "2025-08-22T01:54:36.767Z",
      "attachments": []
    },
    {
      "id": "30sm3d7k",
      "title": "Only Gripper Control From the Script ",
      "content": "# --- Robotiq 85 single-joint control (init-safe, frame-update loop, holds arm targets) ---\n\nimport time\nimport numpy as np\n\nfrom isaacsim.core.api import World\nfrom isaacsim.core.utils.types import ArticulationAction  # kept for reference; not used now\nfrom isaacsim.robot.manipulators import SingleManipulator\ntry:\n    from isaacsim.core.articulations import ArticulationView\nexcept Exception:\n    from omni.isaac.core.articulations import ArticulationView\n\nimport omni.kit.app\nimport omni.timeline\n\n# === Your scene paths ===\nROBOT_PRIM_PATH = \"/World/ur\"\nEE_LINK_PATH    = \"/World/ur/wrist_3_link/flange/tool0\"\nGRIPPER_JOINT   = \"robotiq_85_left_knuckle_joint\"\n\nOPEN_POS   = 0.00\nCLOSED_POS = 0.8\nSTEP       = 0.01\n\n# Reuse (or create) World\ntry:\n    world = World.instance()\nexcept Exception:\n    world = World(stage_units_in_meters=1.0)\n\nBASE_NAME = \"__robotiq_single_joint_manip__\"\nVIEW_NAME = \"__robotiq_robot_view__\"\n\n# 1) Ensure an ArticulationView exists and physics is initialized\nview = world.scene.get_object(VIEW_NAME)\nif view is None:\n    view = ArticulationView(prim_paths_expr=ROBOT_PRIM_PATH, name=VIEW_NAME)\n    world.scene.add(view)\n\n# Initialize physics handles (idempotent)\ntry:\n    world.initialize_physics()\nexcept Exception:\n    world.reset()\n\n# 2) Wrap the articulation (non-destructive) and add if missing\nmanip = world.scene.get_object(BASE_NAME)\nif manip is None:\n    manip = SingleManipulator(\n        prim_path=ROBOT_PRIM_PATH,\n        name=BASE_NAME,\n        end_effector_prim_path=EE_LINK_PATH,\n        gripper=None,\n    )\n    world.scene.add(manip)\n\n# Resolve joint index\njoint_names = manip.dof_names\nname_to_idx = {n: i for i, n in enumerate(joint_names)}\nif GRIPPER_JOINT not in name_to_idx:\n    print(\"[robotiq] Joint not found:\", GRIPPER_JOINT)\n    print(\"[robotiq] Available DOFs:\", joint_names)\n    raise RuntimeError(\"Update GRIPPER_JOINT.\")\nJIDX = name_to_idx[GRIPPER_JOINT]\nLOW, HIGH = (min(OPEN_POS, CLOSED_POS), max(OPEN_POS, CLOSED_POS))\n\n# 3) Frame update loop (holds all joints; moves only gripper target)\napp = omni.kit.app.get_app()\ntimeline = omni.timeline.get_timeline_interface()\n\n# Clean old subscription on re-runs\nold_sub = getattr(manip, \"_robotiq_sub\", None)\nif old_sub is not None:\n    try:\n        old_sub.unsubscribe()\n    except Exception:\n        pass\n\n_state = {\n    \"i\": 0,\n    \"targets\": None,   # full joint position targets we will keep updating\n}\n\ndef _clamp(v, lo, hi):\n    return lo if v < lo else hi if v > hi else v\n\ndef _on_update(e):\n    # Drive only while sim time advances\n    if not timeline.is_playing():\n        return\n\n    # Read current joint positions (needed once to seed targets)\n    q = manip.get_joint_positions()\n    if q is None or len(q) == 0:\n        return  # wait until PhysX buffers exist\n\n    # Seed & latch the hold targets on first valid frame\n    if _state[\"targets\"] is None:\n        _state[\"targets\"] = q.copy()\n        # Hold the current pose for all joints\n        view.set_joint_position_targets(_state[\"targets\"][None, :])  # shape (1, dof)\n        return  # start moving next frame\n\n    # Update only the gripper target; hold everything else\n    i = _state[\"i\"]\n    if i < 500:\n        _state[\"targets\"][JIDX] = _clamp(_state[\"targets\"][JIDX] + STEP, LOW, HIGH)  # closing\n    else:\n        _state[\"targets\"][JIDX] = _clamp(_state[\"targets\"][JIDX] - STEP, LOW, HIGH)  # opening\n\n    # Apply the full target vector (controller will hold arm joints at their targets)\n    view.set_joint_position_targets(_state[\"targets\"][None, :])\n\n    _state[\"i\"] = 0 if i >= 999 else i + 1\n\n# Subscribe to per-frame updates (Script Editor friendly)\nmanip._robotiq_sub = app.get_update_event_stream().create_subscription_to_pop(\n    _on_update, name=f\"__robotiq_update_{int(time.time())%100000}\"\n)\n\n# Start timeline so updates fire and physics initializes\ntimeline.play()\n\nprint(f\"[robotiq] Holding arm joints and cycling '{GRIPPER_JOINT}' between {OPEN_POS} and {CLOSED_POS}.\")\n\n# --- Utilities: update the same targets vector ---\ndef _ensure_targets():\n    if _state[\"targets\"] is None:\n        q = manip.get_joint_positions()\n        if q is not None and len(q) > 0:\n            _state[\"targets\"] = q.copy()\n            view.set_joint_position_targets(_state[\"targets\"][None, :])\n            return True\n        print(\"[robotiq] Joint state not ready yet.\")\n        return False\n    return True\n\ndef gripper_set(alpha: float):\n    \"\"\"Set gripper between open (0.0) and closed (1.0) and hold all other joints.\"\"\"\n    if not _ensure_targets():\n        return\n    a = float(np.clip(alpha, 0.0, 1.0))\n    target = OPEN_POS * (1.0 - a) + CLOSED_POS * a\n    _state[\"targets\"][JIDX] = _clamp(target, LOW, HIGH)\n    view.set_joint_position_targets(_state[\"targets\"][None, :])\n    print(f\"[robotiq] Set alpha={a:.2f} -> {target:.3f}\")\n\ndef gripper_open():\n    if not _ensure_targets():\n        return\n    _state[\"targets\"][JIDX] = OPEN_POS\n    view.set_joint_position_targets(_state[\"targets\"][None, :])\n    print(\"[robotiq] Open.\")\n\ndef gripper_close():\n    if not _ensure_targets():\n        return\n    _state[\"targets\"][JIDX] = CLOSED_POS\n    view.set_joint_position_targets(_state[\"targets\"][None, :])\n    print(\"[robotiq] Close.\")\n\ndef gripper_stop_loop():\n    sub = getattr(manip, \"_robotiq_sub\", None)\n    if sub is not None:\n        try:\n            sub.unsubscribe()\n            print(\"[robotiq] Stopped auto loop.\")\n        except Exception:\n            print(\"[robotiq] Could not unsubscribe (already gone?).\")\n",
      "tags": [],
      "projectId": "x58sfrwh",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-21T19:52:30.132Z",
      "updatedAt": "2025-08-21T22:53:59.515Z",
      "attachments": []
    },
    {
      "id": "n4dczvok",
      "title": "Python Script for Controlling the Ur5e + Robotiq Gripper",
      "content": "```python\n#!/usr/bin/env python3\n# --- Robotiq 85 single-joint control (standalone, auto-resolve UR root & EE link) ---\n\nfrom isaacsim import SimulationApp\nimport argparse, time, numpy as np\n\nparser = argparse.ArgumentParser(description=\"Robotiq 85 single-joint loop on a UR articulation (auto-resolve prims).\")\nparser.add_argument(\"--headless\", action=\"store_true\", help=\"Run headless.\")\nparser.add_argument(\"--stage\", type=str, default=None, help=\"Open an existing stage (.usd/.usda/.usdz).\")\nparser.add_argument(\"--spawn-ur-usd\", type=str, default=None, help=\"USD to reference at /World/ur on a fresh stage.\")\nparser.add_argument(\"--ur-prim\", type=str, default=\"/World/ur\", help=\"Expected robot root prim path (coarse).\")\nparser.add_argument(\"--ee-link\", type=str, default=\"/World/ur/wrist_3_link/flange/tool0\", help=\"End-effector prim path guess.\")\nparser.add_argument(\"--gripper-joint\", type=str, default=\"robotiq_85_left_knuckle_joint\", help=\"Robotiq single DOF name.\")\nparser.add_argument(\"--open-pos\", type=float, default=0.0, help=\"Open position.\")\nparser.add_argument(\"--closed-pos\", type=float, default=0.8, help=\"Closed position.\")\nparser.add_argument(\"--step\", type=float, default=0.01, help=\"Per-step delta.\")\nparser.add_argument(\"--ground\", action=\"store_true\", help=\"Add a default ground plane.\")\nparser.add_argument(\"--quit-after\", type=float, default=None, help=\"Quit after N seconds (for CI/tests).\")\nargs, _ = parser.parse_known_args()\n\nsimulation_app = SimulationApp({\"headless\": bool(args.headless)})\n\n# ----- Imports that need SimulationApp alive\ntry:\n    from isaacsim.core.api import World\n    from isaacsim.core.utils.types import ArticulationAction\n    from isaacsim.robot.manipulators import SingleManipulator\nexcept Exception:\n    from omni.isaac.core import World\n    from omni.isaac.core.utils.types import ArticulationAction\n    from omni.isaac.core.robots import SingleManipulator\n\ntry:\n    from isaacsim.core.articulations import ArticulationView\nexcept Exception:\n    from omni.isaac.core.articulations import ArticulationView\n\nimport omni.usd\nfrom pxr import Usd, Sdf\ntry:\n    from isaacsim.core.utils.stage import add_reference_to_stage\nexcept Exception:\n    add_reference_to_stage = None\n\n# ----- USD helpers\ndef _stage(): return omni.usd.get_context().get_stage()\ndef _open_stage(path: str):\n    ctx = omni.usd.get_context(); ctx.open_stage(path)\n    for _ in range(200):\n        st = ctx.get_stage()\n        if st and st.GetRootLayer(): return st\n        omni.kit.app.get_app().update()\n    return ctx.get_stage()\ndef _new_stage():\n    ctx = omni.usd.get_context(); ctx.new_stage(); return ctx.get_stage()\ndef _add_ref(usd_path: str, prim_path: str):\n    if add_reference_to_stage: add_reference_to_stage(usd_path=usd_path, prim_path=prim_path); return\n    st = _stage(); prim = st.DefinePrim(prim_path, \"Xform\"); prim.GetReferences().AddReference(usd_path)\n\ndef _exists(path: str) -> bool:\n    st = _stage(); \n    return bool(st and st.GetPrimAtPath(path).IsValid())\n\ndef _search_suffix(root: str, suffix: str) -> str|None:\n    \"\"\"Find first prim under `root` whose path ends with `suffix`.\"\"\"\n    st = _stage(); rprim = st.GetPrimAtPath(root)\n    if not rprim.IsValid(): return None\n    for prim in Usd.PrimRange(rprim):\n        if prim.GetPath().pathString.endswith(suffix):\n            return prim.GetPath().pathString\n    return None\n\ndef _find_articulation_root_under(root_hint: str) -> str|None:\n    \"\"\"Heuristic: many UR assets mount a child prim (e.g., '/World/ur/ur'). Try common depths and pick the first that has joints.\"\"\"\n    if _exists(root_hint): return root_hint\n    leaf = Sdf.Path(root_hint).name\n    cand = Sdf.Path(root_hint).AppendChild(leaf).pathString\n    if _exists(cand): return cand\n    st = _stage()\n    base = st.GetPrimAtPath(Sdf.Path(root_hint).GetParentPath())\n    if base and base.IsValid():\n        for prim in base.GetChildren():\n            pstr = prim.GetPath().pathString\n            if pstr.startswith(root_hint) and any(True for _ in prim.GetChildren()):\n                return pstr\n    return None\n\n# ----- Stage setup\nif args.stage and args.spawn_ur_usd:\n    print(\"[robotiq] Both --stage and --spawn-ur-usd given; opening --stage and ignoring spawn.\")\nif args.stage:\n    print(f\"[robotiq] Opening stage: {args.stage}\")\n    _open_stage(args.stage)\nelif args.spawn_ur_usd:\n    print(\"[robotiq] Creating fresh stage and spawning UR USD at /World/ur\")\n    _new_stage()\n    _add_ref(args.spawn_ur_usd, \"/World/ur\")\nelse:\n    print(\"[robotiq] No --stage/--spawn-ur-usd; creating empty stage (will error if robot not present).\")\n    _new_stage()\n\nworld = World(stage_units_in_meters=1.0)\nif args.ground:\n    try: world.scene.add_default_ground_plane()\n    except Exception: pass\n\n# ----- Auto-resolve actual robot root & EE link\nur_root = _find_articulation_root_under(args.ur_prim) or args.ur_prim\nif not _exists(ur_root):\n    st = _stage()\n    roots = [p.GetPath().pathString for p in st.GetPseudoRoot().GetChildren()]\n    print(\"[robotiq] Could not locate robot root under:\", args.ur_prim)\n    print(\"[robotiq] Top-level prims:\", roots[:12])\n    simulation_app.close(); raise SystemExit(1)\n\nee_link = args.ee_link\nif not _exists(ee_link):\n    try_rebased = ee_link.replace(args.ur_prim, ur_root)\n    candidates = [\n        try_rebased,\n        f\"{ur_root}/wrist_3_link/flange/tool0\",\n        f\"{ur_root}/wrist_3_link/tool0\",\n        f\"{ur_root}/wrist_3_link/flange\",\n    ]\n    ee_link = next((p for p in candidates if _exists(p)), None)\n    if not ee_link:\n        ee_link = _search_suffix(ur_root, \"tool0\")\n    if not ee_link or not _exists(ee_link):\n        print(\"[robotiq] End-effector prim not found.\")\n        print(\"  Tried:\", [c for c in candidates])\n        print(\"  Searched for suffix: tool0 under\", ur_root)\n        simulation_app.close(); raise SystemExit(1)\n\nprint(f\"[robotiq] Using robot root: {ur_root}\")\nprint(f\"[robotiq] Using EE link:   {ee_link}\")\n\n# ----- Scene objects\nVIEW_NAME = \"__robotiq_robot_view__\"\nview = world.scene.get_object(VIEW_NAME)\nif view is None:\n    view = ArticulationView(prim_paths_expr=ur_root, name=VIEW_NAME)\n    world.scene.add(view)\n\nMANIP_NAME = \"__robotiq_single_joint_manip__\"\nmanip = world.scene.get_object(MANIP_NAME)\nif manip is None:\n    manip = SingleManipulator(prim_path=ur_root, name=MANIP_NAME, end_effector_prim_path=ee_link, gripper=None)\n    world.scene.add(manip)\n\nworld.reset()\n\n# ----- Resolve gripper joint index\njoint_names = manip.dof_names\nname_to_idx = {n: i for i, n in enumerate(joint_names)}\nif args.gripper_joint not in name_to_idx:\n    print(\"[robotiq] Joint not found:\", args.gripper_joint)\n    print(\"[robotiq] Available DOFs:\", joint_names)\n    simulation_app.close(); raise SystemExit(1)\nJIDX = name_to_idx[args.gripper_joint]\n\nOPEN_POS, CLOSED_POS, STEP = float(args.open_pos), float(args.closed_pos), float(args.step)\nLOW, HIGH = (min(OPEN_POS, CLOSED_POS), max(OPEN_POS, CLOSED_POS))\ndef _clamp(v, lo, hi): return lo if v < lo else hi if v > hi else v\n\nprint(f\"[robotiq] Controlling '{args.gripper_joint}' idx={JIDX}, limits=[{LOW:.3f},{HIGH:.3f}], step={STEP:.4f}\")\n\n# ----- Main loop\ni, reset_needed, t0 = 0, False, time.time()\nwhile simulation_app.is_running():\n    world.step(render=not args.headless)\n\n    if world.is_stopped() and not reset_needed:\n        reset_needed = True\n    if world.is_playing():\n        if reset_needed:\n            world.reset(); reset_needed = False\n\n        q = manip.get_joint_positions()\n        if q is None or len(q) == 0:\n            continue\n\n        if i < 500:  q[JIDX] = _clamp(q[JIDX] + STEP, LOW, HIGH)   # closing\n        else:        q[JIDX] = _clamp(q[JIDX] - STEP, LOW, HIGH)   # opening\n        manip.apply_action(ArticulationAction(joint_positions=q.tolist()))\n        i = 0 if i >= 999 else i + 1\n\n    if args.quit_after is not None and (time.time() - t0) >= float(args.quit_after):\n        break\n\nsimulation_app.close()\n",
      "tags": [],
      "projectId": "x58sfrwh",
      "dateIndex": null,
      "type": "note",
      "pinned": false,
      "createdAt": "2025-08-22T02:25:43.608Z",
      "updatedAt": "2025-08-22T02:25:43.608Z",
      "attachments": []
    },
    {
      "id": "1itn31si",
      "title": "2025-08-22 — Daily",
      "content": "# Top 3\n- [ ] \n- [ ] \n- [ ] \n\n## Tasks\n\n## Journal\n\n## Wins\n",
      "tags": [],
      "projectId": null,
      "dateIndex": "2025-08-22",
      "type": "daily",
      "pinned": false,
      "createdAt": "2025-08-22T13:32:29.630Z",
      "updatedAt": "2025-08-22T13:32:29.630Z",
      "attachments": []
    }
  ],
  "tasks": [
    {
      "id": "0u8o1eca",
      "title": "Setting up HTC Vive",
      "status": "BACKLOG",
      "due": null,
      "noteId": "rfn667g2",
      "projectId": null,
      "priority": "low",
      "createdAt": "2025-08-13T17:29:06.625Z",
      "completedAt": null
    },
    {
      "id": "uy8ut5pn",
      "title": "Import URDF to Issac Sim",
      "status": "DONE",
      "due": null,
      "noteId": "rfn667g2",
      "projectId": null,
      "priority": "low",
      "createdAt": "2025-08-13T17:29:44.617Z",
      "completedAt": "2025-08-15T01:39:36.875Z"
    },
    {
      "id": "uj15mv6j",
      "title": "ROS2 Lifecycle Nodes",
      "status": "BACKLOG",
      "due": null,
      "noteId": "rfn667g2",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-13T17:44:37.113Z",
      "completedAt": null
    },
    {
      "id": "wxswgz5p",
      "title": "ROS2 Behavioural Trees",
      "status": "BACKLOG",
      "due": null,
      "noteId": "rfn667g2",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-13T17:45:08.475Z",
      "completedAt": null
    },
    {
      "id": "tg105zjb",
      "title": "Startup script to run MBWH servers",
      "status": "BACKLOG",
      "due": null,
      "noteId": "rfn667g2",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-13T19:59:53.634Z",
      "completedAt": null
    },
    {
      "id": "7s3eebu4",
      "title": "Test Pymoveit2 with Joint Limits",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "lpliw12c",
      "priority": "medium",
      "createdAt": "2025-08-13T20:01:48.445Z",
      "completedAt": null
    },
    {
      "id": "vwmmg0x8",
      "title": "Modularize planner & Integrate with Demoq2 code",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "lpliw12c",
      "priority": "medium",
      "createdAt": "2025-08-13T20:02:39.354Z",
      "completedAt": null
    },
    {
      "id": "z6i0jhtm",
      "title": "Improve the models",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "a7732c0q",
      "priority": "medium",
      "createdAt": "2025-08-13T20:05:19.538Z",
      "completedAt": null
    },
    {
      "id": "abt35u13",
      "title": "Enable the option to do plain Point Prompting to segmentation model",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "a7732c0q",
      "priority": "medium",
      "createdAt": "2025-08-13T20:08:48.163Z",
      "completedAt": null
    },
    {
      "id": "7ldaxaco",
      "title": "Complete and Integrate Tracking service",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "a7732c0q",
      "priority": "medium",
      "createdAt": "2025-08-13T20:09:08.331Z",
      "completedAt": null
    },
    {
      "id": "xkasv32m",
      "title": "Re-setup the Issac Sim/Lab env",
      "status": "DONE",
      "due": null,
      "noteId": "rfn667g2",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-13T21:33:22.892Z",
      "completedAt": "2025-08-15T01:40:42.059Z"
    },
    {
      "id": "4067wm8u",
      "title": "Re-setup the Issac Sim/Lab env",
      "status": "DONE",
      "due": null,
      "noteId": "5zkaojpo",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-14T17:01:30.445Z",
      "completedAt": "2025-08-15T01:40:43.387Z"
    },
    {
      "id": "jstgmz3u",
      "title": "https://youtu.be/r2_VWdjxchY?si=2-tXkllKBZvJv5Tt",
      "status": "DONE",
      "due": null,
      "noteId": "5zkaojpo",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-14T17:06:33.457Z",
      "completedAt": "2025-08-14T18:23:52.218Z"
    },
    {
      "id": "2pnquqmp",
      "title": "https://www.linkedin.com/posts/chriskielthy_hiring-robotics-gtm-activity-7361411215106949121-3PNG?utm_source=share&utm_medium=member_android&rcm=ACoAABmYRCwB4VRjjDiSREanVW4-OL2NFsUjdi0",
      "status": "DONE",
      "due": null,
      "noteId": "5zkaojpo",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-14T17:07:26.962Z",
      "completedAt": "2025-08-14T18:25:31.467Z"
    },
    {
      "id": "7sfsdayh",
      "title": "Import URDF to Issac Sim",
      "status": "DONE",
      "due": null,
      "noteId": "5zkaojpo",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-14T17:07:55.187Z",
      "completedAt": "2025-08-14T18:26:02.530Z"
    },
    {
      "id": "wj4wqv99",
      "title": "Learn about Evaluation Metrics for a policy",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "c7szb5bi",
      "priority": "medium",
      "createdAt": "2025-08-14T17:14:42.644Z",
      "completedAt": null
    },
    {
      "id": "62yl3gtp",
      "title": "Implement own data collection and training script",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "c7szb5bi",
      "priority": "medium",
      "createdAt": "2025-08-14T17:15:17.419Z",
      "completedAt": null
    },
    {
      "id": "ks950odn",
      "title": "Setup personal Robot Learning Setup",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "c7szb5bi",
      "priority": "medium",
      "createdAt": "2025-08-14T17:20:42.155Z",
      "completedAt": null
    },
    {
      "id": "6rwu7cpo",
      "title": "Re-setup the Issac Sim/Lab env",
      "status": "DONE",
      "due": null,
      "noteId": "dddvyov0",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-19T06:21:48.203Z",
      "completedAt": "2025-08-20T01:36:48.981Z"
    },
    {
      "id": "s8lp8mrw",
      "title": "Test the movement of UR5e in joint space",
      "status": "DONE",
      "due": null,
      "noteId": "1l4evqz6",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-15T01:49:03.559Z",
      "completedAt": "2025-08-15T21:53:02.697Z"
    },
    {
      "id": "paee3k8n",
      "title": "Attempt the need to fix the path issues for mesh files",
      "status": "BACKLOG",
      "due": null,
      "noteId": "tho7b72v",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-18T04:21:34.898Z",
      "completedAt": null
    },
    {
      "id": "6fruuw7m",
      "title": "Establish teleoperation in Isaacsim",
      "status": "DONE",
      "due": null,
      "noteId": "m99i6s3b",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-18T01:11:18.417Z",
      "completedAt": "2025-08-18T03:30:54.904Z"
    },
    {
      "id": "x71zad37",
      "title": "Teleoperation Literature Review",
      "status": "DONE",
      "due": null,
      "noteId": "dddvyov0",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-19T06:21:48.203Z",
      "completedAt": "2025-08-19T21:28:17.442Z"
    },
    {
      "id": "tblf1kqz",
      "title": "https://youtu.be/TY9CYRBOBPM?si=9e3YROBT0UmlHOxT",
      "status": "DONE",
      "due": null,
      "noteId": "tho7b72v",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-18T04:21:34.898Z",
      "completedAt": "2025-08-18T19:28:04.421Z"
    },
    {
      "id": "cn7l4wwb",
      "title": "Learn and Build TMux start for the scripts",
      "status": "BACKLOG",
      "due": null,
      "noteId": "1l4evqz6",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-15T17:33:55.528Z",
      "completedAt": null
    },
    {
      "id": "2ksol9ec",
      "title": "Assemble the robot - ur5e + robotiq",
      "status": "DONE",
      "due": null,
      "noteId": "m99i6s3b",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-18T01:11:18.417Z",
      "completedAt": "2025-08-20T01:39:41.340Z"
    },
    {
      "id": "coz35syb",
      "title": "Test the visuals from UR10E on UR5E to improve realism",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "x58sfrwh",
      "priority": "medium",
      "createdAt": "2025-08-18T17:37:49.540Z",
      "completedAt": null
    },
    {
      "id": "jk451t6h",
      "title": "https://m.youtube.com/watch?v=32uzEGpvSog",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null
    },
    {
      "id": "ab9cibgb",
      "title": "https://ai.meta.com/dinov3/",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null
    },
    {
      "id": "wik2kohf",
      "title": "Learn how to design and create flexible or deformable assets for simulation.",
      "status": "BACKLOG",
      "due": null,
      "noteId": null,
      "projectId": "x58sfrwh",
      "priority": "medium",
      "createdAt": "2025-08-20T20:26:33.074Z",
      "completedAt": null
    },
    {
      "id": "zpq74ow8",
      "title": "Complete Isaac Sim Documentaion",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null
    },
    {
      "id": "dfi95qh3",
      "title": "Complete Teleoperation Survey",
      "status": "DONE",
      "due": null,
      "noteId": "rhsvuali",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-21T15:56:02.845Z",
      "completedAt": "2025-08-22T02:49:41.960Z"
    },
    {
      "id": "3l5qcby0",
      "title": "Master Robot Assembly process and Document the learning",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null
    },
    {
      "id": "m4t60tmt",
      "title": "Quick Test one RL policy training pipeline using the assembled UR5E + Robotiq Gripper",
      "status": "TODO",
      "due": null,
      "noteId": null,
      "projectId": "c7szb5bi",
      "priority": "medium",
      "createdAt": "2025-08-20T20:33:58.595Z",
      "completedAt": null
    },
    {
      "id": "9w2vvens",
      "title": "Control the gripper thorugh Python code",
      "status": "DONE",
      "due": null,
      "noteId": "rhsvuali",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-21T15:56:02.845Z",
      "completedAt": "2025-08-22T02:49:47.192Z"
    },
    {
      "id": "nj4fsr56",
      "title": "https://www.linkedin.com/posts/rohinik_hiring-remote-activity-7363790536115179525-2pVJ?utm_source=share&utm_medium=member_android&rcm=ACoAABmYRCwB4VRjjDiSREanVW4-OL2NFsUjdi0",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null
    },
    {
      "id": "607tsrll",
      "title": "Test ROS2 working in Isaaclab",
      "status": "TODO",
      "due": null,
      "noteId": null,
      "projectId": "c7szb5bi",
      "priority": "medium",
      "createdAt": "2025-08-21T15:57:49.242Z",
      "completedAt": null
    },
    {
      "id": "uwtaz1rx",
      "title": "Test1",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null,
      "deletedAt": "2025-08-22T01:06:56.684Z"
    },
    {
      "id": "ylyckeso",
      "title": "Test1",
      "status": "TODO",
      "due": "2025-08-23",
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "high",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null,
      "deletedAt": "2025-08-22T01:08:47.077Z"
    },
    {
      "id": "be4wi3cd",
      "title": "test4",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "low",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null,
      "deletedAt": "2025-08-22T01:08:42.483Z"
    },
    {
      "id": "yiznuxwv",
      "title": "testtest",
      "status": "TODO",
      "due": "2025-08-23",
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null,
      "deletedAt": "2025-08-22T01:08:44.628Z"
    },
    {
      "id": "l96onb2e",
      "title": "est4",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.649Z",
      "completedAt": null,
      "deletedAt": "2025-08-22T01:08:53.508Z"
    },
    {
      "id": "odtb3d35",
      "title": "Tedx",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-22T13:32:29.650Z",
      "completedAt": null
    },
    {
      "id": "ijgs71ek",
      "title": "Test2",
      "status": "TODO",
      "due": null,
      "noteId": null,
      "projectId": "lpliw12c",
      "priority": "medium",
      "createdAt": "2025-08-23T01:02:14.955Z",
      "completedAt": null,
      "deletedAt": "2025-08-23T01:02:28.746Z"
    },
    {
      "id": "4u0h5lb9",
      "title": "Test2",
      "status": "TODO",
      "due": null,
      "noteId": null,
      "projectId": "lpliw12c",
      "priority": "medium",
      "createdAt": "2025-08-23T01:02:47.422Z",
      "completedAt": null,
      "deletedAt": "2025-08-23T01:02:49.255Z"
    },
    {
      "id": "z8hc14hm",
      "title": "Test2",
      "status": "TODO",
      "due": null,
      "noteId": "1itn31si",
      "projectId": null,
      "priority": "medium",
      "createdAt": "2025-08-23T01:04:39.703Z",
      "completedAt": null,
      "deletedAt": "2025-08-23T01:04:43.195Z"
    }
  ],
  "templates": [
    {
      "id": "tpl1",
      "name": "Meeting Notes",
      "content": "# Meeting: [Title]\n**Date:** [Date]\n**Attendees:** \n\n## Agenda\n- \n\n## Notes\n\n## Action Items\n- [ ] \n\n## Next Steps\n"
    },
    {
      "id": "tpl2",
      "name": "Project Plan",
      "content": "# [Project Name]\n\n## Objective\n\n## Goals\n- \n\n## Milestones\n- [ ] \n\n## Resources\n\n## Risks\n\n## Success Metrics\n"
    },
    {
      "id": "tpl3",
      "name": "Weekly Review",
      "content": "# Week of [Date]\n\n## Wins\n- \n\n## Challenges\n- \n\n## Lessons Learned\n- \n\n## Next Week Focus\n- [ ] \n"
    },
    {
      "id": "tpl4",
      "name": "Brainstorming Session",
      "content": "# Brainstorming Session: [Topic]\n**Date:** [Date]\n**Facilitator:** [Name]\n\n## Ideas\n- \n\n## Discussion Points\n- \n\n## Action Items\n- [ ] \n"
    },
    {
      "id": "tpl5",
      "name": "Research Summary",
      "content": "# Research Summary: [Topic]\n\n## Objective\n\n## Key Findings\n- \n\n## Implications\n\n## Next Steps\n"
    },
    {
      "id": "tpl6",
      "name": "Course / Lecture Notes",
      "content": "# Course / Lecture: [Title]\n**Course:** [Course]\n**Module / Week:** \n**Date:** [Date]\n**Instructor:** \n\n## Session Overview\nBrief summary...\n\n## Key Concepts\n- Term: Definition\n- \n\n## Detailed Notes\n- \n\n## Examples / Demonstrations\n- \n\n## Important Formulas / Patterns\n```\n\n```\n\n## Questions / Clarifications Needed\n- [ ] \n\n## Action Items / Practice\n- [ ] \n\n## References\n- \n\n## Summary (1–2 sentences)\n\n"
    },
    {
      "id": "tpl7",
      "name": "Project Execution Log",
      "content": "# Project Execution Log: [Project Name]\n**Date:** [Date]\n**Phase / Sprint:** \n\n## Context\nCurrent objective / scope.\n\n## Goals for This Session\n- [ ] \n\n## Procedure / Steps Performed\n1. \n2. \n\n## Commands / Tools Used\n```\n# command snippets\n```\n\n## Issues Encountered\n| Issue | Impact | Resolution |\n|-------|--------|------------|\n|  |  |  |\n\n## Decisions Made\n- Decision: Rationale\n\n## Metrics / Measurements\n- \n\n## Observations / Insights\n- \n\n## Risks / Blockers\n- \n\n## Artifacts / Outputs\n- \n\n## Next Actions\n- [ ] \n\n## Retrospective (What went well / improve)\n- Went well: \n- Improve: \n\n"
    }
  ],
  "links": [
    {
      "id": "u8o69pqs",
      "title": "MolmoAct: An Action Reasoning Model that reasons in 3D space",
      "url": "https://allenai.org/blog/molmoact",
      "tags": [
        "page"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-13T16:14:54.249Z",
      "updatedAt": "2025-08-14T16:02:41.007Z"
    },
    {
      "id": "7fxrnsg7",
      "title": "Custom Controller for ROS2",
      "url": "https://github.com/masum919/my_custom_controller",
      "tags": [
        "repo"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-13T16:15:35.656Z",
      "updatedAt": "2025-08-14T16:02:18.982Z"
    },
    {
      "id": "vbslbow1",
      "title": "Sampling-Based Model Predictive Control for Dexterous Manipulation on a Biomimetic Tendon-Driven Hand",
      "url": "https://arxiv.org/pdf/2411.06183",
      "tags": [
        "paper"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-13T22:34:54.894Z",
      "updatedAt": "2025-08-13T22:34:54.894Z"
    },
    {
      "id": "3cctlmkm",
      "title": "Cognitive Robotics - MIT Course",
      "url": "https://m.youtube.com/playlist?list=PLUl4u3cNGP62Bkdzwe7caTZC7soj7ZYvk",
      "tags": [
        "course"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-14T14:10:33.123Z",
      "updatedAt": "2025-08-14T14:10:33.123Z"
    },
    {
      "id": "4dhli9tl",
      "title": "Wev Viewer for Robotics",
      "url": "https://mechaverse.dev/",
      "tags": [
        "web",
        "viewer",
        "urdf",
        "robotics"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-15T23:36:24.138Z",
      "updatedAt": "2025-08-15T23:36:24.138Z"
    },
    {
      "id": "tr0zmntl",
      "title": "Moveit2 with Isaac Sim & Gazebo",
      "url": "https://github.com/blackcoffeerobotics/bcr_arm/",
      "tags": [
        "motionplanning",
        "digitaltwin",
        "ros",
        "moveit2",
        "isaacsim"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-18T01:15:39.613Z",
      "updatedAt": "2025-08-18T01:15:39.613Z"
    },
    {
      "id": "1syawn9i",
      "title": "Robotics101 from VisCircuit",
      "url": "https://robotics101-viscircuit.web.app/robotics/numerical-methods-for-ode",
      "tags": [
        "tutorial",
        "robotics",
        "webviz",
        "web",
        "course"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-18T01:17:01.730Z",
      "updatedAt": "2025-08-18T01:17:01.730Z"
    },
    {
      "id": "21i1056m",
      "title": "AI Sheets from Huggingface",
      "url": "https://huggingface.co/spaces/aisheets/sheets",
      "tags": [
        "llm",
        "huggingface",
        "sheets",
        "syntheticdata",
        "dataset"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-18T15:19:41.040Z",
      "updatedAt": "2025-08-18T15:19:41.040Z"
    },
    {
      "id": "08x4aado",
      "title": "Multiverse - Decentralised Simulation Framework",
      "url": "https://github.com/Multiverse-Framework/Multiverse",
      "tags": [
        "simulation",
        "digitaltwin",
        "robotics"
      ],
      "pinned": false,
      "status": "NEW",
      "createdAt": "2025-08-20T19:51:10.181Z",
      "updatedAt": "2025-08-20T19:51:10.181Z"
    }
  ],
  "monthly": [
    {
      "id": "vu1anz40",
      "title": "Tedx",
      "days": [
        0,
        1,
        2,
        3,
        4,
        5,
        6
      ],
      "month": "2025-08",
      "createdAt": "2025-08-22T01:14:49.338Z"
    },
    {
      "id": "zhjf8cae",
      "title": "Thinkschool",
      "days": [
        0,
        1,
        2,
        3,
        4,
        5,
        6
      ],
      "month": "2025-08",
      "createdAt": "2025-08-22T17:30:01.128Z"
    },
    {
      "id": "38lyvswq",
      "title": "Reading Book",
      "days": [
        1,
        3,
        5
      ],
      "month": "2025-08",
      "createdAt": "2025-08-23T01:15:26.176Z"
    }
  ]
}